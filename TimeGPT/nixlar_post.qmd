
---
title: "A First Look at TimeGPT"
author: "Joseph Rickert"
date: 2024-12-13
description: ""
image: ""
image-alt: ""
categories: ""
editor: source
---

This post is a first look at [Nixtla's](https://docs.nixtla.io/) `TimeGPT` generative, pre-trained transformer for time series forecasting.

According to [Garza et al. (2021)](https://arxiv.org/abs/2111.04052), TimeGPT is a Transformer-based time series model with self-attention mechanisms. The architecture comprises an encoder-decoder structure with multiple layers, each with residual connections and layer normalization. The encoder, a stack of multi-head self-attention layers followed by a feed-forward neural network, processes the input time series. The decoder, which is similar to the encoder, generates the forecast. The decoder includes an additional multi-head attention layer that takes the encoder’s output as input. The model is trained using a teacher-forcing strategy, where the decoder receives the ground-truth values during training. The model is then used for forecasting by feeding the model’s predictions back as input during inference.

![](timegpt.png){fig-alt="TimeGPT architecture"}


Nixtla's website provides a considerable amount of explanatory material, documentation, and code examples in Python. The [`nixlar`](https://cran.r-project.org/package=nixtlar) package wraps the Python code to provide an R interface. The package documentation for version 0.6.2 doesn't fully the R functions, but the vignettes provide sufficient code examples to get started.

*Before getting started with TimeGPT you will have to register for an API key. The process is easy enough and is described in this [vignette](https://cran.r-project.org/web/packages/nixtlar/vignettes/setting-up-your-api-key.html).*



```{r}
#| message: FALSE
#| message: FALSE
library(tidyverse)
library(forecast)
library(xts)
library(prophet)
library(nixtlar)
```


```{r}
# saveRDS(nixtla_fcst, "nixtla_fcst.rds")
nixt_fcst <- readRDS("nixtla_fcst.rds")
# saveRDS(nixtla_hist_fcst, "nixtla_hist_fcst.rds")
nixt_hist_fcst <- readRDS("nixtla_hist_fcst.rds")
# saveRDS(nixtla_client_fcst, "nixtla_client_fcst.rds")
nixtla_client_fcst <- readRDS("nixtla_client_fcst.rds")
```

### The Data

We will use the electricity dataset provided with the `nixtlar` package that contains a total of 61,320 observations of hourly electricity consumption generated from 2012 to 2018 for five different markets New York markets. So there are five different time series. You can see that the various time series do not cover the same time periods.

```{r}
df <- nixtlar::electricity
df_wide <- df |> 
  pivot_wider(names_from = unique_id, values_from = y) 
head(df_wide)
```

A plot will give you a good feel for the data.
```{r}
df2 <- df |> mutate( time = as.POSIXct(ds, format = "%Y-%m-%d %H:%M:%S")) |> 
                     group_by(unique_id)
p <- df2 |> ggplot(aes(x = time, y = y, color = unique_id)) +
           geom_line() + facet_wrap(~unique_id, scales = "free")
p
```


### Forecasting

we will start out by showining off the `nixtlar` forecasting function which can handle multiple time series. The parameter `h` specifies the number of steps ahead to forecast, and `level` specifies parameter that the confidence level for the forecast.

```{r}
# nixtla_client_fcst <- nixtla_client_forecast(df, h = 8, level = c(80,95))
nixtla_client_fcst <- readRDS("nixtla_client_fcst.rds")
ncf_df <-  nixtla_client_fcst |> mutate( time = as.POSIXct(ds, format = "%Y-%m-%d %H:%M:%S")) |> group_by(unique_id)
names(ncf_df) <- c("unique_id", "ds", "TimeGPT",  "lon", "loe", "hie", "hin")
pf <- ncf_df |> ggplot(aes(x = ds, y = TimeGPT, color = unique_id)) +
           geom_line() +
           geom_ribbon(aes(ymin=lon, ymax=hin), linetype=2, alpha=0.1) +
           facet_wrap(~unique_id, scales = "free") 
pf
```


For the rest of this post we will work only with the BE data and do some simple back testing. We will split the data into training set and a test set containing 24 hours worth of observations. We will then fit several time series forecasting models and compare how well they do vis a vis the actual data and with each other. 

```{r}
NF <- 24
BE_df_wide <- df |> pivot_wider(names_from = unique_id, values_from = y) |>
                    select(ds,BE) |> drop_na()
BE_train_df <- BE_df_wide %>% filter(row_number() <= n()-NF)
BE_test_df <- tail(BE_df_wide,NF)
BE_train_df <- BE_train_df |> rename(y = BE) |> mutate(unique_id = "BE")
BE_test_df <- BE_test_df |> rename(y = BE)
```


We start of with the TemeGPT forecast.

```{r}
#| message: FALSE
#| message: FALSE
nixtla_fcst <- nixtla_client_forecast(BE_train_df, h = NF, level = 95)
names(nixtla_fcst) <- c("unique_id", "ds", "TimeGPT", "lo95", "up95")

```

Create the data frame to hold the actual and forecast values
```{r}
#| message: FALSE
#| message: FALSE
fcst_df <- tail(nixtla_fcst,NF) |> select(ds,TimeGPT) |> 
           rename(time = ds, tgpt_fcst = TimeGPT) |>
           mutate(elec_actual = BE_test_df$y)
head(fcst_df)
```


### ARIMA Forecast with `auto.arima()`

```{r}
arima_train <- BE_train_df |> select(-unique_id) |>
               mutate( time = as.POSIXct(ds, format = "%Y-%m-%d %H:%M:%S"))
arima_train <- arima_train |> select(-ds)

elec_ts <- as.xts(arima_train)

arima_fcst <- elec_ts |> 
  auto.arima() |>
  # number of periods to forecast
  forecast(h =NF , level = 95)
```


### Exponential smoothing forecast with `ets()`
```{r}
ets_fcst <- elec_ts |> 
  ets() |>
  # number of periods to forecast
  forecast(h = NF)
```




```{r}
#| message: FALSE
#| message: FALSE
prophet_fit <- prophet(BE_train_df)
future <- make_future_dataframe(prophet_fit, periods = NF,  freq = 3600, include_history = FALSE)
prophet_fcst <- predict(prophet_fit, future)
```



```{r}
fcst_df2 <- fcst_df |>
             mutate(arima_fcst = as.vector(arima_fcst$mean),
                    ets_fcst = as.vector(ets_fcst$mean),
                    prophet_fcst = prophet_fcst$yhat)
head(fcst_df2)
```


```{r}
fcst_dft2_long <- fcst_df2 %>%
  pivot_longer(!time, names_to = "method", values_to = "mean")

q <- fcst_dft2_long |> ggplot(aes(x = time, y = mean, group = method, color = method)) +
                        geom_line() +
                        geom_point() +
                        ggtitle("TimeGPT vs ARIMA vs ETS vs Prophet vs actual data") 
q
```








